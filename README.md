[![CI](https://github.com/Alxjq-afk/my-ml/actions/workflows/ci.yml/badge.svg)](https://github.com/Alxjq-afk/my-ml/actions/workflows/ci.yml)

# ML + JARVIS Assistant

Proyecto integrado con dos componentes principales:

## üìä 1. Machine Learning (train.py / predict.py)

Entrenamiento e inferencia de modelos de IA.

## ü§ñ 2. JARVIS Assistant (Advanced Voice v2.0)

Asistente de voz tipo Cortana/Alexa con:
- **Escucha continua** con detecci√≥n de palabra clave ("Hey JARVIS")
- **Speech-to-Text** con Whisper (OpenAI)
- **Modelos de lenguaje**: Mistral 7B local + Hugging Face remoto
- **Comandos naturales**: "abre notepad", "sube volumen", etc.
- **APIs integradas**: hora, clima, b√∫squeda web, info del sistema
- **Text-to-Speech**: respuestas de voz

**Documentaci√≥n completa**: Ver [`JARVIS_ADVANCED.md`](JARVIS_ADVANCED.md)

---

## üöÄ Quick Start

### JARVIS (Voice Assistant)
```bash
# Modo texto (CLI)
python run_jarvis_voice.py --mode cli

# Modo voz (escucha continua)
python run_jarvis_voice.py --mode voice

# Modo h√≠brido (auto-detecta)
python run_jarvis_voice.py
```

**Ejemplo de comandos**:
```
"abre notepad"          ‚Üí Abre Notepad
"ejecuta dir C:\"       ‚Üí Ejecuta comando
"sube volumen a 70"     ‚Üí Ajusta volumen
"¬øQu√© hora es?"         ‚Üí Pregunta a JARVIS
```

### ML Training
```bash
python train.py --epochs 20 --batch-size 32
python predict.py --model model_final.pt --input test_data.csv
```

---

## üì¶ Contenido del proyecto:
- `train.py`: script de entrenamiento que utiliza PyTorch si est√° instalado; si no, usa scikit-learn (MLP) como fallback. Dataset por defecto: `digits` de scikit-learn (peque√±o y sin descargas).
- `requirements.txt`: dependencias m√≠nimas.
- `predict.py`: script de inferencia para modelos guardados (PyTorch `.pt` o sklearn `.joblib/.pkl`).
- `.github/workflows/ci.yml`: workflow de CI que ejecuta los tests con `pytest`.

C√≥mo usar (PowerShell):

1) Crear/activar tu entorno virtual (opcional pero recomendado):

    python -m venv .venv; .\.venv\Scripts\Activate.ps1

2) Instalar dependencias m√≠nimas:

    pip install -r requirements.txt

Si quieres usar PyTorch (opcional): visita https://pytorch.org/get-started/locally/ para instalar la versi√≥n adecuada para tu sistema.

3) Ejecutar el script:

    python train.py

Notas:
- Si PyTorch est√° instalado, el script entrenar√° una peque√±a red en PyTorch (CPU/GPU si est√° disponible).
- Si PyTorch no est√° instalado, el script entrenar√° un `MLPClassifier` de scikit-learn sobre el dataset `digits`.

Caracter√≠sticas incluidas en esta versi√≥n:
- Guardado de checkpoints y modelos (PyTorch: `checkpoint_epoch{N}.pt`, `model_final.pt`; sklearn: `sklearn_mlp.joblib` / `sklearn_mlp.pkl`).
- Reanudaci√≥n desde checkpoint (`--resume`) para PyTorch.
- Early stopping y separaci√≥n train/val/test (`--val-size`, `--patience`, `--monitor`).
- Soporte opcional de TensorBoard (`--tb`) para registrar m√©tricas.
- `predict.py` para hacer inferencia con los modelos guardados.
- Tests unitarios con `pytest` y workflow de CI (`.github/workflows/ci.yml`).

Siguientes pasos recomendados (opcionales):
- Sustituir `load_digits` por un dataset propio o por `torchvision.datasets` para datasets m√°s grandes.
- Integrar Weights & Biases (W&B) u otro sistema de tracking para experimentos.

Detalles y ejemplos de uso
-------------------------

El script ahora acepta varios argumentos desde la l√≠nea de comandos (usa `python train.py --help` para verlos todos):

- `--epochs` (int): n√∫mero de √©pocas (por defecto 10)
- `--batch-size` (int): tama√±o de batch (por defecto 64)
- `--lr` (float): learning rate (por defecto 1e-3)
- `--save-dir` (str): directorio donde guardar checkpoints y modelos
- `--save-every` (int): cada N √©pocas guardar checkpoint (PyTorch)
- `--backend` (auto|torch|sklearn): forzar backend (por defecto `auto`)
- `--device` (auto|cpu|cuda): forzar dispositivo (solo PyTorch)
- `--seed` (int): semilla para reproducibilidad (random, numpy, torch)
- `--resume` (str): ruta a checkpoint PyTorch para reanudar entrenamiento

Flags nuevos para validaci√≥n y early stopping
-------------------------------------------

- `--val-size` (float): fracci√≥n del dataset usada para validaci√≥n (por defecto 0.1). El dataset se divide en train/val/test.
- `--patience` (int): paciencia para early stopping (n√∫mero de epochs sin mejora antes de detenerse). Por defecto 3.
- `--monitor` (accuracy|loss): m√©trica a monitorizar para decidir mejoras y guardar el mejor modelo. Por defecto `accuracy`.

Ejemplos con early stopping y validaci√≥n
---------------------------------------

- Entrenar con validaci√≥n y early stopping (PyTorch):

    python train.py --epochs 50 --val-size 0.15 --patience 5 --save-dir checkpoints_es

- Forzar backend scikit-learn con early stopping y TensorBoard logging:

    python train.py --backend sklearn --val-size 0.15 --patience 5 --tb --save-dir checkpoints_skes

Notas sobre early stopping
-------------------------

- El script ahora separa el dataset en train/val/test. La validaci√≥n se usa para monitorizar la m√©trica indicada en `--monitor`.
- Si no hay mejora durante `--patience` epochs, el entrenamiento se detiene y el mejor checkpoint (seg√∫n la m√©trica) queda en `--save-dir`.


Ejemplos pr√°cticos (PowerShell):

- Entrenar 20 √©pocas en el backend detectado (PyTorch si est√° instalado):

    python train.py --epochs 20 --batch-size 64 --lr 0.001

- Guardar checkpoints en `checkpoints` cada 2 √©pocas:

    python train.py --save-dir checkpoints --save-every 2 --epochs 10

- Forzar uso de CPU y fijar semilla para reproducibilidad:

    python train.py --device cpu --seed 42 --save-dir checkpoints

- Reanudar desde un checkpoint guardado (PyTorch):

    python train.py --resume checkpoints\checkpoint_epoch3.pt --save-dir checkpoints --epochs 10

- Forzar backend scikit-learn (usa joblib/pickle para guardar el modelo):

    python train.py --backend sklearn --save-dir checkpoints_sklearn

Notas sobre `--resume` y guardado
--------------------------------

- Cuando usas `--resume` con un checkpoint generado por PyTorch, el script intentar√° cargar el estado del modelo y tambi√©n el estado del optimizador (si est√° presente). Si el estado del optimizador no es compatible por diferencias de versi√≥n, el script continuar√° desde el modelo cargado pero podr√≠a no restaurar exactamente el optimizador.
- Los checkpoints de PyTorch se guardan como `checkpoint_epoch{N}.pt` y el modelo final como `model_final.pt` en `--save-dir`.
- El backend sklearn guarda `sklearn_mlp.joblib` y `scaler.joblib` (si `joblib` est√° disponible). Si joblib no funciona, se guarda un `sklearn_mlp.pkl` con pickle como fallback.

Recomendaciones r√°pidas
---------------------

- Si tienes GPU y quieres usarla, instala PyTorch con soporte CUDA desde la web oficial; el script usar√° autom√°ticamente `cuda` si est√° disponible a menos que pases `--device cpu`.
- Para experimentos reproducibles, fija `--seed` y anota la versi√≥n de las librer√≠as (p. ej. `pip freeze > requirements-freeze.txt`).
- Si quieres monitorizaci√≥n, puedo a√±adir TensorBoard o integraci√≥n con Weights & Biases en el siguiente paso.

Si quieres que a√±ada integraci√≥n con Weights & Biases, m√°s tests (p. ej. cobertura para PyTorch), ejemplos de configuraci√≥n (`yaml`) o pipelines de deployment, dime qu√© prefieres y lo implemento.

Integraci√≥n continua (CI)
-------------------------

Este repositorio incluye un workflow de GitHub Actions en `.github/workflows/ci.yml` que instala las dependencias desde `requirements.txt` y ejecuta la suite de tests (`pytest`). Cada push y pull request contra `main`/`master` activar√° el CI.

